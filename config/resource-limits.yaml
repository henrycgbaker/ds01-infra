# DS01 GPU Server - Resource Limits Configuration
# /opt/ds01-infra/config/resource-limits.yaml

# This file controls default and per-user/group resource allocations

# Default limits for all users (unless overridden below)
defaults:
  # GPU limits
  max_mig_instances: 2              # Max MIG instances user can have allocated simultaneously (TODO: check if this is across all containers!)
  gpu_memory: null                  # GPU memory limit in GB (null = no limit, already enforced by MIG)
  
  # Compute limits (per container)
  max_cpus: 16                          # CPU cores per container
  memory: 32g                       # RAM limit per container
  memory_swap: 32g                  # Swap limit (should match memory to prevent swap)
  shm_size: 16g                     # Shared memory (important for PyTorch DataLoader)
  pids_limit: 4096                  # Max processes (prevents fork bombs)
  
  # Storage limits (enforced via disk quotas)
  storage_workspace: 100G           # Max storage in /workspace/$USER
  storage_data: 200G                # Max storage in /data/$USER
  storage_tmp: 50G                  # Max storage in /tmp (inside container)
  
  # Container lifecycle
  max_containers_per_user: 3        # Max simultaneous containers
  idle_timeout: 48h                 # Auto-stop after X hours of GPU inactivity
  max_runtime: null                 # Max walltime (null = no limit)
  
  max_tasks: 512                    # Max tasks for systemd slice
  
  # Priority for allocation (1=lowest, 100=highest)
  priority: 1

default_group: student

# User group definitions
groups:
  student:
    members: []  # TO DO: autopopulate from LDAP group 'ds01-students'
    max_mig_instances: 2            # Can use max 2 MIG instances simultaneously
    max_cpus: 16
    memory: 32g
    storage_workspace: 100G
    storage_data: 200G
    idle_timeout: 48h
    max_runtime: 168h               # 1 week max
    priority: 10                    # Low priority
    
  researcher:
    members: []  
    max_mig_instances: 8            # Can use up to 4 MIG instances or 1 full GPU
    max_cpus: 32
    memory: 64g
    memory_swap: 64g
    shm_size: 32g
    storage_workspace: 500G
    storage_data: 1T
    idle_timeout: 48h              # 1 week
    max_runtime: null               # No limit
    max_tasks: 2048
    max_containers_per_user: 5
    priority: 50                    # Medium priority
    
  admin:
    members: [datasciencelab]  
    max_mig_instances: null         # Unlimited (can use all GPUs)
    max_cpus: 64
    memory: 128g
    memory_swap: 128g
    shm_size: 64g
    storage_workspace: 2T
    storage_data: 5T
    idle_timeout: null              # No timeout
    max_runtime: null               # No limit
    max_containers_per_user: 10
    max_tasks: null
    priority: 90                    # High priority

# Per-user overrides (takes precedence over group settings)
# These have HIGHEST priority (100) and can reserve resources
user_overrides:
  # Example time-based reservation:
  # john_doe:
  #   max_mig_instances: 1
  #   memory: 64g
  #   priority: 100                 # Highest priority (reserved)
  #   reservation_start: "2025-11-01T00:00:00"
  #   reservation_end: "2025-11-08T00:00:00"
  #   reserved_gpus: [0]            # Reserve specific GPU IDs
  #   reason: "Thesis deadline - needs dedicated GPU for 1 week"

# GPU allocation strategy
gpu_allocation:
  strategy: least_allocated         # Options: least_allocated, round_robin, priority_aware
  allocation_method: dynamic        # Allocate on container start, not permanent assignment
  
  # MIG (Multi-Instance GPU) configuration for A100s
  enable_mig: true                  # Enable MIG partitioning
  mig_strategy: auto                # auto, manual, disabled
  mig_profile: 2g.20gb              # MIG profile (3 instances per A100)
                                    # Options: 1g.10gb (7 instances), 2g.20gb (3 instances), 3g.40gb (2 instances)
  
  # When to use full GPU vs MIG:
  # - Students: Always get MIG instances
  # - Researchers: Get MIG instances unless requesting full GPU explicitly
  # - Admins: Can request full GPU or MIG instances
  
  # Priority-aware allocation:
  # 1. Check for active reservations (priority 100)
  # 2. Allocate by user priority (admin=90, researcher=50, student=10)
  # 3. Within same priority, use least_allocated strategy
  
  respect_reservations: true        # Honor user_override reservations
  
# Container lifecycle policies
policies:
  auto_stop_idle: true
  checkpoint_warning: 36h           # Warn users X hours before auto-stop
  require_workspace_mount: true     # Force all containers to mount /workspace
  enforce_storage_quotas: true      # Enable disk quotas
  
  # Error handling
  graceful_errors: true             # Show helpful error messages when limits exceeded
  suggest_alternatives: true        # Suggest alternatives when resource unavailable
  
# Advanced settings
advanced:
  enable_mps: false                 # MPS (Multi-Process Service) - disabled when MIG enabled
  network_mode: host                # or 'bridge'
  restart_policy: unless-stopped

# Wizard defaults (for interactive setup) TODO: move this to a script
wizard:
  default_mig_count: 1              # Default MIG request in wizard
  recommended_mig_count: 1          # Recommended MIG count shown to users
  max_mig_warning_threshold: 4      # Warn if requesting more than this
  
  # Error messages for common scenarios
  error_messages:
    mig_limit_exceeded: |
      ❌ GPU Limit Exceeded
      
      You requested {requested} MIG instances, but your limit is {max} MIGs.
      You currently have {current} MIGs allocated.
      
      Options:
      1. Reduce your MIG request to {available} or fewer
      2. Stop an existing container to free up GPUs
      3. Launch this container without GPU (CPU-only)
      
      Check your current allocations: ds01-gpu-status
      
    container_limit_exceeded: |
      ❌ Container Limit Exceeded
      
      You already have {current} containers running.
      Your limit is {max} containers.
      
      Please stop a container before creating a new one:
        mlc-stop <container-name>
      
    no_gpu_available: |
      ⚠️ No GPUs Available
      
      All GPUs are currently allocated to other users.
      
      Options:
      1. Wait for a GPU to become available
      2. Launch as CPU-only container for now
      3. Check GPU status: ds01-gpu-status
      
    reservation_conflict: |
      ❌ GPU Reserved
      
      The requested GPU is reserved for {reserved_user} until {end_time}.
      Reason: {reason}
      
      Please try a different GPU or wait for the reservation to end.
